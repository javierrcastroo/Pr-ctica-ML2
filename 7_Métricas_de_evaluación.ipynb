{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuXbNw3ckcaE"
      },
      "source": [
        "# 7 - Métricas de evaluación\n"
      ],
      "id": "tuXbNw3ckcaE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6dHeG2PkcaI"
      },
      "source": [
        "## Preparación del entorno\n",
        "Fijamos semillas, comprobamos versiones y definimos utilidades.\n"
      ],
      "id": "X6dHeG2PkcaI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NDElehSkcaI"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, load_digits, load_diabetes\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,\n",
        "    accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score,\n",
        "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
        "    matthews_corrcoef, log_loss, brier_score_loss, classification_report,\n",
        "    mean_squared_error, mean_absolute_error, r2_score)\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "\n",
        "import json, os, sys, platform, random"
      ],
      "id": "0NDElehSkcaI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "Mu9INTCAklIk"
      },
      "id": "Mu9INTCAklIk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1iKf6sjkcaJ"
      },
      "source": [
        "## 1. Preparación para clasificación (binaria)\n",
        "\n",
        "**Dataset**: `load_breast_cancer`"
      ],
      "id": "H1iKf6sjkcaJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t122Nh2VkcaJ"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "data = load_breast_cancer(as_frame=True)\n",
        "df_bin = data.frame.copy()\n",
        "X_bin = df_bin.drop(columns=['target'])\n",
        "y_bin = df_bin['target']\n",
        "\n",
        "display(df_bin.head(3))\n",
        "print(f\"Dimensiones: {X_bin.shape}\\n\\nDistribución del {y_bin.value_counts(normalize=True)}\")"
      ],
      "id": "t122Nh2VkcaJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un **holdout estratificado 60/20/20** (Train/Valid/Test)"
      ],
      "metadata": {
        "id": "hmFAS13GleiG"
      },
      "id": "hmFAS13GleiG"
    },
    {
      "cell_type": "code",
      "source": [
        "X_tmp, X_test, y_tmp, y_test = train_test_split(X_bin, y_bin, test_size=0.2, stratify=y_bin, random_state=SEED)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_tmp, y_tmp, test_size=0.25, stratify=y_tmp, random_state=SEED)\n",
        "\n",
        "print(f\"Train:\\t\\t{len(X_train)} registros; tasa de prevalencia: {y_train.mean():.4f}\")\n",
        "print(f\"Validation:\\t{len(X_valid)} registros; tasa de prevalencia: {y_valid.mean():.4f}\")\n",
        "print(f\"Test:\\t\\t{len(X_test)} registros; tasa de prevalencia: {y_test.mean():.4f}\")"
      ],
      "metadata": {
        "id": "gbiR_8_aleMp"
      },
      "id": "gbiR_8_aleMp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTZOj9GokcaK"
      },
      "source": [
        "Se crea un **pipeline base** que se mantendrá a lo largo de las secciones para garantizar compatibilidad.\n"
      ],
      "id": "UTZOj9GokcaK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbMEqLETkcaK"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "pipe_bin = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=SEED))\n",
        "])\n",
        "pipe_bin"
      ],
      "id": "jbMEqLETkcaK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos el entrenamiento mediante el pipeline con los datos de train, y obtenemos las **probabilidades predichas** para la clase positiva (target=1) en los conjuntos de **validación** y **test**."
      ],
      "metadata": {
        "id": "EE6QHQWbm8T9"
      },
      "id": "EE6QHQWbm8T9"
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_bin.fit(X_train, y_train)\n",
        "\n",
        "proba_valid = pipe_bin.predict_proba(X_valid)[:,1]\n",
        "proba_test  = pipe_bin.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(f\"Media de 10 probabilidades predichas en validación: {round(proba_valid[:10].mean(), 3)}\")"
      ],
      "metadata": {
        "id": "OsKJlc_1mpRO"
      },
      "id": "OsKJlc_1mpRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhcLARnskcaK"
      },
      "source": [
        "## 2. Matriz de confusión\n",
        "\n",
        "Con umbral **τ = 0.5** calculamos la matriz de confusión en validación."
      ],
      "id": "hhcLARnskcaK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer el umbral y aplicarlo a las predicciones\n",
        "tau = 0.5\n",
        "yhat_valid = (proba_valid >= tau).astype(int)"
      ],
      "metadata": {
        "id": "IED6KFh3prYl"
      },
      "id": "IED6KFh3prYl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generación de la matriz de confusión\n",
        "cm = confusion_matrix(y_valid, yhat_valid, labels=[1,0])\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['Positivo','Negativo'])\n",
        "fig, ax = plt.subplots(figsize=(4,4)); disp.plot(ax=ax, colorbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ayyILH_apsqm"
      },
      "id": "ayyILH_apsqm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fWcrMQBkcaL"
      },
      "source": [
        "## 3. Métricas básicas (τ = 0.5)\n",
        "\n",
        "* **Accuracy:** mide aciertos globales.\n",
        "* **Precisión (PPV):** usado para minimizar FP.\n",
        "* **Recall (TPR):** usado para minimizar FN.\n",
        "* **Especificidad (TNR):** usado para minimizar FP también, aunque con otro enfoque.\n",
        "* **FPR y FNR:** tasas de error por clase."
      ],
      "id": "0fWcrMQBkcaL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEaCvXldkcaL"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_valid, yhat_valid)\n",
        "prec = precision_score(y_valid, yhat_valid, zero_division=0)\n",
        "rec = recall_score(y_valid, yhat_valid)\n",
        "tn, fp, fn, tp = confusion_matrix(y_valid, yhat_valid).ravel()\n",
        "spec = tn / (tn + fp)\n",
        "fpr = fp / (fp + tn)\n",
        "fnr = fn / (fn + tp)\n",
        "\n",
        "print(\"Métricas Básicas (τ = 0.5):\")\n",
        "print(f\"  Accuracy: {acc:.4f}\")\n",
        "print(f\"  Precision: {prec:.4f}\")\n",
        "print(f\"  Recall (TPR): {rec:.4f}\")\n",
        "print(f\"  Specificity (TNR): {spec:.4f}\")\n",
        "print(f\"  FPR: {fpr:.4f}\")\n",
        "print(f\"  FNR: {fnr:.4f}\")"
      ],
      "id": "MEaCvXldkcaL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUKQzrSHkcaL"
      },
      "source": [
        "## 4. Métricas avanzadas\n",
        "\n",
        "* **F1**: media armónica de Precisión y Recall.\n",
        "* **Fβ**: pondera más el Recall cuando β > 1.\n",
        "* **Balanced Accuracy**: media de TPR y TNR (útil con desbalance).\n",
        "* **MCC**: Coeficiente de Correlación de Matthews (robusto con desbalance).\n"
      ],
      "id": "dUKQzrSHkcaL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiH-o7gzkcaL"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "f1 = f1_score(y_valid, yhat_valid)\n",
        "bal_acc = balanced_accuracy_score(y_valid, yhat_valid)\n",
        "mcc = matthews_corrcoef(y_valid, yhat_valid)\n",
        "\n",
        "# Cálculo manual de F_beta\n",
        "def fbeta_score_manual(y_true, y_pred, beta=2.0):\n",
        "    p = precision_score(y_true, y_pred, zero_division=0); r = recall_score(y_true, y_pred)\n",
        "    b2 = beta**2\n",
        "    return (1 + b2) * p * r / (b2 * p + r + 1e-12)\n",
        "f2 = fbeta_score_manual(y_valid, yhat_valid, beta=2.0)\n",
        "\n",
        "print(\"Métricas Avanzadas:\")\n",
        "print(f\"  F1: {f1:.4f}\")\n",
        "print(f\"  F2: {f2:.4f}\")\n",
        "print(f\"  Balanced Accuracy: {bal_acc:.4f}\")\n",
        "print(f\"  MCC: {mcc:.4f}\")"
      ],
      "id": "JiH-o7gzkcaL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCfPOedPkcaL"
      },
      "source": [
        "## 5. Multiclase: micro / macro / weighted"
      ],
      "id": "eCfPOedPkcaL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset:** `load_digits` tiene 10 clases.\n",
        "\n",
        "Se realiza un holdout estratificado y se entrena mediante un pipeline sencillo.\n"
      ],
      "metadata": {
        "id": "9-wLRlp3aC3l"
      },
      "id": "9-wLRlp3aC3l"
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits(as_frame=True)\n",
        "Xd, yd = digits.data, digits.target\n",
        "Xd_tr, Xd_te, yd_tr, yd_te = train_test_split(Xd, yd, test_size=0.2, stratify=yd, random_state=SEED)\n",
        "\n",
        "pipe_mc = Pipeline(\n",
        "    [('imp', SimpleImputer(strategy='median')),\n",
        "     ('scaler', StandardScaler()),\n",
        "     ('clf', LogisticRegression(max_iter=2000, multi_class='auto', random_state=SEED))])\n",
        "\n",
        "pipe_mc.fit(Xd_tr, yd_tr)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gxZNLwvsaJr4"
      },
      "id": "gxZNLwvsaJr4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos F1-score **micro**, **macro** y **weighted**."
      ],
      "metadata": {
        "id": "qs3vgvK5an_c"
      },
      "id": "qs3vgvK5an_c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWqfil60kcaM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "yd_pred = pipe_mc.predict(Xd_te)\n",
        "\n",
        "f1_micro = f1_score(yd_te, yd_pred, average='micro')\n",
        "f1_macro = f1_score(yd_te, yd_pred, average='macro')\n",
        "f1_weighted = f1_score(yd_te, yd_pred, average='weighted')\n",
        "\n",
        "print(f\"F1-score (micro): {f1_micro:.4f}\")\n",
        "print(f\"F1-score (macro): {f1_macro:.4f}\")\n",
        "print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "print('\\nReporte de clasificación automático:\\n')\n",
        "print(classification_report(yd_te, yd_pred))  # recorte visual"
      ],
      "id": "OWqfil60kcaM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOkA2rrOkcaM"
      },
      "source": [
        "---\n",
        "## 6. Curva ROC y AUC-ROC (binaria)\n",
        "Calculamos la curva ROC en Validación y su AUC.\n"
      ],
      "id": "LOkA2rrOkcaM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRNUcpYkcaM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "fpr, tpr, thr = roc_curve(y_valid, proba_valid)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.5f}')\n",
        "plt.plot([0,1],[0,1],'--')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('Curva ROC - Validación')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "lDRNUcpYkcaM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_vQpOWXkcaM"
      },
      "source": [
        "---\n",
        "## 7. Curva Precision-Recall y AUC-PR (binaria)\n",
        "Útil cuando la clase positiva es rara o cuando queremos controlar falsos positivos.\n"
      ],
      "id": "d_vQpOWXkcaM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuoIZkfRkcaM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "prec_curve, rec_curve, thr_pr = precision_recall_curve(y_valid, proba_valid)\n",
        "ap = average_precision_score(y_valid, proba_valid)\n",
        "baseline = y_valid.mean()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(rec_curve, prec_curve, label=f'AP = {ap:.5f}')\n",
        "plt.hlines(baseline, 0, 1, linestyles='--', label=f'Baseline (prevalencia) ={baseline:.2f}', color='orange')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall - Validación')\n",
        "plt.legend(loc='center left')\n",
        "plt.show()"
      ],
      "id": "TuoIZkfRkcaM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFC7HplMkcaM"
      },
      "source": [
        "## 8. Métricas basadas en probabilidad: Log-loss y Brier\n",
        "Penalizan probabilidades mal calibradas (no solo el orden).\n"
      ],
      "id": "bFC7HplMkcaM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3erKJ6DNkcaM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "ll_valid = log_loss(y_valid, proba_valid)\n",
        "brier_valid = brier_score_loss(y_valid, proba_valid)\n",
        "\n",
        "ll_test = log_loss(y_test, proba_test)\n",
        "brier_test = brier_score_loss(y_test, proba_test)\n",
        "\n",
        "print(\"Métricas basadas en probabilidad:\")\n",
        "print(f\"  Log-loss:\")\n",
        "print(f\"    Validación:\\t{ll_valid:.4f}\")\n",
        "print(f\"    Test:\\t{ll_test:.4f}\")\n",
        "print(f\"  Brier Score:\")\n",
        "print(f\"    Validación:\\t{brier_valid:.4f}\")\n",
        "print(f\"    Test:\\t{brier_test:.4f}\")"
      ],
      "id": "3erKJ6DNkcaM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp-Z_MItkcaM"
      },
      "source": [
        "## 9. Selección de umbral\n"
      ],
      "id": "cp-Z_MItkcaM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza un barrido **τ ∈ [0,1]** para buscar aquel que maximice F1-score en Validación."
      ],
      "metadata": {
        "id": "R42ewJBieISu"
      },
      "id": "R42ewJBieISu"
    },
    {
      "cell_type": "code",
      "source": [
        "taus = np.linspace(0,1,101)\n",
        "f1s, precs, recs = [], [], []\n",
        "\n",
        "for t in taus:\n",
        "    yhat = (proba_valid >= t).astype(int)\n",
        "    f1s.append(f1_score(y_valid, yhat))\n",
        "    precs.append(precision_score(y_valid, yhat, zero_division=0))\n",
        "    recs.append(recall_score(y_valid, yhat))\n",
        "\n",
        "best_idx = int(np.nanargmax(f1s))\n",
        "tau_star = float(taus[best_idx])\n",
        "print(f\"Mejor umbral (conjunto Validación): {tau_star}\")"
      ],
      "metadata": {
        "id": "oJi5ubtteTh4"
      },
      "id": "oJi5ubtteTh4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(taus, f1s, label='F1')\n",
        "plt.axvline(tau_star, linestyle='--', label=f'tau*={tau_star:.2f}', color='orange')\n",
        "plt.xlabel('Umbral')\n",
        "plt.ylabel('Métrica')\n",
        "plt.title('Barrido de umbral en Validación')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i6WGZnfneiKQ"
      },
      "id": "i6WGZnfneiKQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se reportan las métricas en **Test** con ese umbral fijo."
      ],
      "metadata": {
        "id": "KLErgRo9fFiH"
      },
      "id": "KLErgRo9fFiH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXVuomrnkcaM"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "yhat_test = (proba_test >= tau_star).astype(int)\n",
        "\n",
        "print(f\"Métricas en Test con umbral óptimo ({tau_star:.2f}):\")\n",
        "print(f\"  F1: {f1_score(y_test, yhat_test):.4f}\")\n",
        "print(f\"  Precisión: {precision_score(y_test, yhat_test, zero_division=0):.4f}\")\n",
        "print(f\"  Recall: {recall_score(y_test, yhat_test):.4f}\")"
      ],
      "id": "GXVuomrnkcaM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyjbv47mkcaN"
      },
      "source": [
        "## 10. Calibración de probabilidades\n"
      ],
      "id": "fyjbv47mkcaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se **calibra** usando solo el **Train** (con cross-validation interno)"
      ],
      "metadata": {
        "id": "_ddCqycrhJ_5"
      },
      "id": "_ddCqycrhJ_5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibramos usando solo el train (con CV interna) y evaluamos en Validación\n",
        "calib = CalibratedClassifierCV(estimator=pipe_bin, method='isotonic', cv=5)\n",
        "calib.fit(X_train, y_train)\n",
        "proba_valid_cal = calib.predict_proba(X_valid)[:,1]"
      ],
      "metadata": {
        "id": "0H0OcGKpfaAp"
      },
      "id": "0H0OcGKpfaAp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Métricas** y **comparación**:\n",
        "\n",
        "En este caso el calibrado nmo ofrece mejores resultados porque el original ya estaba bien calibrado, y el tamaño reducido del dataset implica un mejor potencial del proceso de calibrado."
      ],
      "metadata": {
        "id": "5vsK6ZDwhUny"
      },
      "id": "5vsK6ZDwhUny"
    },
    {
      "cell_type": "code",
      "source": [
        "res = {\n",
        "    'AUC_valid_before': auc(*roc_curve(y_valid, proba_valid)[:2]),\n",
        "    'AUC_valid_after': auc(*roc_curve(y_valid, proba_valid_cal)[:2]),\n",
        "    'Brier_before': brier_score_loss(y_valid, proba_valid),\n",
        "    'Brier_after': brier_score_loss(y_valid, proba_valid_cal),\n",
        "    'LogLoss_before': log_loss(y_valid, proba_valid),\n",
        "    'LogLoss_after': log_loss(y_valid, proba_valid_cal)\n",
        "}\n",
        "\n",
        "print(\"Comparación de Métricas (Validación):\\n\")\n",
        "print(f\"{'Métrica':<20} | {'Antes':<10} | {'Después':<10}\")\n",
        "print(\"-\" * 45)\n",
        "print(f\"{'AUC':<20} | {res['AUC_valid_before']:.4f}     | {res['AUC_valid_after']:.4f}\")\n",
        "print(f\"{'Brier Score':<20} | {res['Brier_before']:.4f}     | {res['Brier_after']:.4f}\")\n",
        "print(f\"{'Log-loss':<20} | {res['LogLoss_before']:.4f}     | {res['LogLoss_after']:.4f}\")"
      ],
      "metadata": {
        "id": "2xJGdd01hXl_"
      },
      "id": "2xJGdd01hXl_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tencjuuskcaN"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "prob_true_b, prob_pred_b = calibration_curve(y_valid, proba_valid, n_bins=10, strategy='uniform')\n",
        "prob_true_c, prob_pred_c = calibration_curve(y_valid, proba_valid_cal, n_bins=10, strategy='uniform')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot([0,1],[0,1],'--', label='Perfectamente calibrado')\n",
        "plt.plot(prob_pred_b, prob_true_b, marker='o', label='Antes')\n",
        "plt.plot(prob_pred_c, prob_true_c, marker='o', label='Después (calibrado)')\n",
        "plt.xlabel('Prob. predicha')\n",
        "plt.ylabel('Frac. positiva real')\n",
        "plt.title('Diagrama de calibración (Validación)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "id": "tencjuuskcaN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsqMW8F6kcaN"
      },
      "source": [
        "## 11. Métricas de regresión (R², MSE/MAE, MAPE/SMAPE)"
      ],
      "id": "AsqMW8F6kcaN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset:** `load_diabetes` porque tiene un target numérico continuo.\n",
        "\n",
        "Se realiza un holdout sencillo y se entrena usando un nuevo pipeline para regresión."
      ],
      "metadata": {
        "id": "qzpFKQOEkY-B"
      },
      "id": "qzpFKQOEkY-B"
    },
    {
      "cell_type": "code",
      "source": [
        "diab = load_diabetes(as_frame=True)\n",
        "Xr, yr = diab.data, diab.target\n",
        "Xr_tr, Xr_te, yr_tr, yr_te = train_test_split(Xr, yr, test_size=0.2, random_state=SEED)\n",
        "pipe_reg = Pipeline([('imp', SimpleImputer()), ('scaler', StandardScaler()), ('model', Ridge())])\n",
        "pipe_reg.fit(Xr_tr, yr_tr)"
      ],
      "metadata": {
        "id": "cr_vOsw1kvUG"
      },
      "id": "cr_vOsw1kvUG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálculo de **métricas**:"
      ],
      "metadata": {
        "id": "fKzZTE0flQ2U"
      },
      "id": "fKzZTE0flQ2U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkRxK2Q-kcaN"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "yr_pred = pipe_reg.predict(Xr_te)\n",
        "\n",
        "mse = mean_squared_error(yr_te, yr_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(yr_te, yr_pred)\n",
        "r2 = r2_score(yr_te, yr_pred)\n",
        "\n",
        "# MAPE y SMAPE (con eps para evitar división por 0)\n",
        "eps = 1e-8\n",
        "mape = np.mean(np.abs((yr_te - yr_pred) / np.maximum(np.abs(yr_te), eps)))\n",
        "smape = np.mean(2 * np.abs(yr_pred - yr_te) / (np.abs(yr_te) + np.abs(yr_pred) + eps))\n",
        "\n",
        "print(\"Métricas de Regresión:\")\n",
        "print(f\"  MSE: {mse:.4f}\")\n",
        "print(f\"  RMSE: {rmse:.4f}\")\n",
        "print(f\"  MAE: {mae:.4f}\")\n",
        "print(f\"  R2: {r2:.4f}\")\n",
        "print(f\"  MAPE: {mape:.4f}\")\n",
        "print(f\"  SMAPE: {smape:.4f}\")"
      ],
      "id": "XkRxK2Q-kcaN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx6ZLj9BkcaN"
      },
      "source": [
        "## Ejercicio\n",
        "\n",
        "1. Utiliza nuevos **datasets** (y pipelines) para replicar el **cálculo de métricas** y gráficos presentes a lo largo de la práctica.\n",
        "2. **Interpreta las métricas** obtenidas y razona sobre su comportamiento al realizar cambios en los pasos del flujo de inferencia."
      ],
      "id": "xx6ZLj9BkcaN"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgZYWnsqoI-f"
      },
      "id": "UgZYWnsqoI-f",
      "execution_count": null,
      "outputs": []
    }
  ]
}