{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eT1BXC08GKq"
      },
      "source": [
        "# 6 - Diseño experimental y particionado de datos\n"
      ],
      "id": "2eT1BXC08GKq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rSDLTFe8GKs"
      },
      "source": [
        "## Preparación del entorno\n"
      ],
      "id": "0rSDLTFe8GKs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_TAgPie8GKs"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer, make_classification\n",
        "from sklearn.model_selection import (train_test_split, StratifiedKFold, RepeatedStratifiedKFold,\n",
        "                                      GroupKFold, LeaveOneGroupOut, cross_val_score,\n",
        "                                      GridSearchCV)\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import json, os, sys, platform, random, time"
      ],
      "id": "P_TAgPie8GKs"
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibilidad\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "metadata": {
        "id": "5SsgzUmwBkMU"
      },
      "id": "5SsgzUmwBkMU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs-8sbnM8GKt"
      },
      "source": [
        "**Dataset:** `load_breast_cancer` (*clasificación binaria)*"
      ],
      "id": "Cs-8sbnM8GKt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAJ8uTHq8GKt"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "data = load_breast_cancer(as_frame=True)\n",
        "\n",
        "df = data.frame.copy()\n",
        "X = df.drop(columns=['target'])\n",
        "y = df['target']\n",
        "\n",
        "display(X.head(3))\n",
        "print(f\"Dimensiones: {X.shape}\\n\\nDistribución del {y.value_counts(normalize=True)}\")"
      ],
      "id": "lAJ8uTHq8GKt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Ejemplo de pipeline estándar\n",
        "Un pipeline mínimo para clasificación binaria con datos numéricos:\n",
        "\n",
        "1) `SimpleImputer(strategy='median')` → 2) `StandardScaler()` → 3) `LogisticRegression()`"
      ],
      "metadata": {
        "id": "BWjPCCjHES9W"
      },
      "id": "BWjPCCjHES9W"
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipe = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=500, random_state=SEED))\n",
        "])\n",
        "final_pipe"
      ],
      "metadata": {
        "id": "iesSgwbCESPp"
      },
      "id": "iesSgwbCESPp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ2DXxbL8GKt"
      },
      "source": [
        "## 2. Conjuntos Train / Validación / Test: roles y reglas\n",
        "Creamos particiones **estratificadas** y guardamos los índices para reproducibilidad.\n"
      ],
      "id": "rJ2DXxbL8GKt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ_V3koa8GKu"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Holdout estratificado: primero Train+Valid vs Test\n",
        "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
        "# Ahora Train vs Valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_tv, y_tv, test_size=0.25, stratify=y_tv, random_state=SEED)  # 0.25 de 0.8 -> 0.2\n",
        "\n",
        "# Guardamos índices para auditoría\n",
        "os.makedirs('artifacts', exist_ok=True)\n",
        "splits = {\n",
        "    'seed': SEED,\n",
        "    'train_idx': X_train.index.to_list(),\n",
        "    'valid_idx': X_valid.index.to_list(),\n",
        "    'test_idx': X_test.index.to_list()\n",
        "}\n",
        "with open('artifacts/holdout_indices.json', 'w') as f:\n",
        "    json.dump(splits, f)\n",
        "\n",
        "print(f\"Número de registros:\\n- Train: {len(X_train)}\\n- Validación: {len(X_valid)}\\n- Test: {len(X_test)}\")\n"
      ],
      "id": "aZ_V3koa8GKu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8STXiMx8GKu"
      },
      "source": [
        "## 3. Holdout simple (baseline)\n",
        "Entrenamos un **pipeline sin fugas** y evaluamos en **Validación** y **Test**.\n"
      ],
      "id": "-8STXiMx8GKu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxhtNXpJ8GKu"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "final_pipe.fit(X_train, y_train)\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "val_auc = roc_auc_score(y_valid, final_pipe.predict_proba(X_valid)[:,1])\n",
        "test_auc = roc_auc_score(y_test, final_pipe.predict_proba(X_test)[:,1])\n",
        "\n",
        "print(f\"AUC conjunto Validación: {round(val_auc, 4)}\")\n",
        "print(f\"AUC conjunto Test: {round(test_auc, 4)}\")"
      ],
      "id": "yxhtNXpJ8GKu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvaEjyg98GKu"
      },
      "source": [
        "## 4. k-fold Cross-Validation (estratificada)\n",
        "Estimamos AUC promediando sobre **K=5** folds estratificados.\n"
      ],
      "id": "zvaEjyg98GKu"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICkowwqV8GKv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "cv5 = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "start = time.time()\n",
        "scores_cv5 = cross_val_score(final_pipe, X, y, cv=cv5, scoring='roc_auc')\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "print(f\"Media AUC: {round(scores_cv5.mean(), 4)}\\nDesv. estándar AUC: {round(scores_cv5.std(), 4)}\")"
      ],
      "id": "ICkowwqV8GKv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwCpBrlh8GKv"
      },
      "source": [
        "## 5. Repeated k-fold (5x3)\n",
        "Reducimos varianza repitiendo el k-fold con **diferentes semillas internas**.\n"
      ],
      "id": "WwCpBrlh8GKv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYIU0q508GKv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "rcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=SEED)\n",
        "\n",
        "start = time.time()\n",
        "scores_rcv = cross_val_score(final_pipe, X, y, cv=rcv, scoring='roc_auc')\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "print(f\"Media AUC: {round(scores_rcv.mean(), 4)}\\nDesv. estándar AUC: {round(scores_rcv.std(), 4)}\")"
      ],
      "id": "vYIU0q508GKv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIR7dKl38GKv"
      },
      "source": [
        "## 6. Demostración de data leakage (incorrecto vs correcto)\n",
        "Comparamos un **protocolo incorrecto** (escalado previo con toda la data) vs. el **protocolo correcto** (escalado dentro del `Pipeline`).\n"
      ],
      "id": "ZIR7dKl38GKv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwD8b_Wm8GKv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# INCORRECTO: transformamos antes del CV (posible fuga)\n",
        "X_scaled_wrong = StandardScaler().fit_transform(X)\n",
        "auc_wrong = cross_val_score(LogisticRegression(max_iter=500, random_state=SEED),\n",
        "                            X_scaled_wrong, y, cv=cv5, scoring='roc_auc')\n",
        "\n",
        "# CORRECTO: escalado dentro del Pipeline\n",
        "auc_right = cross_val_score(final_pipe, X, y, cv=cv5, scoring='roc_auc')\n",
        "\n",
        "print(f\"Media AUC (fuga datos): {round(auc_wrong.mean(), 4)}\")\n",
        "print(f\"Media AUC (correcto): {round(auc_right.mean(), 4)}\")"
      ],
      "id": "OwD8b_Wm8GKv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C80l2a4e8GKv"
      },
      "source": [
        "## 7. Nested Cross-Validation (tuning honesto)\n",
        "Separamos **búsqueda de hiperparámetros** (inner CV) de **estimación** (outer CV).\n"
      ],
      "id": "C80l2a4e8GKv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4iWwZ9U8GKv"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
        "\n",
        "# Optimización de hiperparámetros: veremos el detalle en sesiones posteriores\n",
        "param_grid = {'clf__C': [0.1, 1, 10, 100],\n",
        "              'clf__penalty': ['l2'],\n",
        "              'clf__solver': ['lbfgs', 'liblinear']}\n",
        "search = GridSearchCV(final_pipe, param_grid=param_grid, scoring='roc_auc', cv=inner_cv)\n",
        "\n",
        "start = time.time()\n",
        "nested_scores = cross_val_score(search, X, y, cv=outer_cv, scoring='roc_auc')\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "print(f\"Media AUC: {round(nested_scores.mean(), 4)}\\nDesv. estándar AUC: {round(nested_scores.std(), 4)}\")"
      ],
      "id": "q4iWwZ9U8GKv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HngIhzh-8GKw"
      },
      "source": [
        "## 8. Validación con grupos: GroupKFold y LOGO\n",
        "Simulamos **entidades** para demostrar la validación por grupos.\n"
      ],
      "id": "HngIhzh-8GKw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wum96POs8GKw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Creación de un dataset sintético con 80 grupos de tamaño 10\n",
        "Xg, yg = make_classification(n_samples=800, n_features=15, n_informative=8, n_redundant=2,\n",
        "                              n_clusters_per_class=2, weights=[0.6, 0.4], flip_y=0.02,\n",
        "                              class_sep=1.0, random_state=SEED)\n",
        "groups = np.repeat(np.arange(80), 10)\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "start = time.time()\n",
        "scores_gkf = cross_val_score(final_pipe, Xg, yg, groups=groups, cv=gkf, scoring='roc_auc')\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "print(f\"Media AUC: {round(scores_gkf.mean(), 4)}\\nDesv. estándar AUC: {round(scores_gkf.std(), 4)}\")"
      ],
      "id": "wum96POs8GKw"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75AOZ1Rn8GKw"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "logo = LeaveOneGroupOut()\n",
        "\n",
        "start = time.time()\n",
        "scores_logo = cross_val_score(final_pipe, Xg, yg, groups=groups, cv=logo, scoring='roc_auc')\n",
        "print(f\"Duración: {round(time.time() - start, 2)}s\\n\")\n",
        "\n",
        "print(f\"Nº de iteraciones = Nº de grupos -> {len(scores_logo)}\\n\")\n",
        "print(f\"Media AUC: {round(scores_logo.mean(), 4)}\\nDesv. estándar AUC: {round(scores_logo.std(), 4)}\")"
      ],
      "id": "75AOZ1Rn8GKw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c81uPH_u8GKw"
      },
      "source": [
        "## Ejercicio\n",
        "Implementa un **flujo completo sin fugas** siguiendo estas indicaciones:\n",
        "\n",
        "1. Crea y justifica un **holdout** estratificado (Train/Valid/Test). Reporta AUC en Valid y Test.\n",
        "2. Compara **k-fold (K=5)** y **repeated k-fold (5x3)** con el mismo pipeline. Reporta media y desviación de AUC.\n",
        "3. Realiza **Nested CV** (outer=5, inner=3) con grid de `C` para `LogisticRegression`. Reporta el AUC medio.\n",
        "4. Simula **grupos** (o usa un dataset con entidades) y evalúa **GroupKFold (K=5)** y **LOGO**. Compara estabilidad.\n",
        "5. Demuestra un caso de **data leakage** y su corrección con `Pipeline`.\n",
        "6. Entrega los **índices** de los splits usados (JSON en `artifacts/`).\n"
      ],
      "id": "c81uPH_u8GKw"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3wtlnPWJ9sv"
      },
      "id": "O3wtlnPWJ9sv",
      "execution_count": null,
      "outputs": []
    }
  ]
}